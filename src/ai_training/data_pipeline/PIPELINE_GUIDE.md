# ğŸ”„ æ•°æ®å¤„ç†ç®¡é“å®Œæ•´æ–‡æ¡£

## å¿«é€Ÿå¼€å§‹ï¼ˆ5åˆ†é’Ÿï¼‰

### æœ€ç®€å•çš„ä½¿ç”¨æ–¹å¼
```python
from src.ai_training.data_pipeline import AutoDataPipeline

# ä¸€è¡Œä»£ç ï¼Œæ‰€æœ‰æ•°æ®å¤„ç†æå®š
pipeline = AutoDataPipeline(data_dir='./ai_training_data/day_kline_training')
X_train, y_train, X_val, y_val, X_calibrate, y_calibrate, X_test, y_test, metadata = pipeline.run()

# ç›´æ¥å–‚ç»™æ¨¡å‹
from autogluon.tabular import TabularPredictor
predictor = TabularPredictor(label='trend')
predictor.fit(X_train, y_train)
```

---

## ğŸ“‹ è¿™ä¸ªæ¡†æ¶åšäº†ä»€ä¹ˆï¼Ÿ

**ä½ ä¸éœ€è¦å†æ‰‹åŠ¨å¤„ç†ä»¥ä¸‹äº‹é¡¹ï¼š**

| æ­¥éª¤ | æ¡†æ¶è‡ªåŠ¨å¤„ç† | ä½ æ— éœ€å…³å¿ƒ |
|------|-------------|---------|
| 1ï¸âƒ£ æ•°æ®åŠ è½½ | âœ… è‡ªåŠ¨ä»JSONåŠ è½½ï¼Œå¤„ç†å¤šä¸ªæ•°æ®æº | ä¸éœ€è¦å†™åŠ è½½é€»è¾‘ |
| 2ï¸âƒ£ æ•°æ®éªŒè¯ | âœ… æ£€æŸ¥NaN/Infï¼Œç±»åˆ«å®Œæ•´æ€§ï¼Œç»´åº¦ | ä¸éœ€è¦æ‰‹åŠ¨æ£€æŸ¥ |
| 3ï¸âƒ£ NaNå¤„ç† | âœ… è‡ªåŠ¨ç”¨å‡å€¼å¡«å……ï¼Œè®°å½•å¤„ç†è¯¦æƒ… | ä¸éœ€è¦å†³å®šå¦‚ä½•å¤„ç† |
| 4ï¸âƒ£ ç‰¹å¾å·¥ç¨‹ | âœ… è‡ªåŠ¨ç”Ÿæˆè¯­ä¹‰åŒ–ç‰¹å¾åï¼ˆK0_openç­‰ï¼‰ | ä¸éœ€è¦å†™ç‰¹å¾å¤„ç† |
| 5ï¸âƒ£ æ ‡å‡†åŒ– | âœ… StandardScalerè‡ªåŠ¨fit/transform | ä¸éœ€è¦æ‰‹åŠ¨è°ƒç”¨ |
| 6ï¸âƒ£ æ•°æ®åˆ†å‰² | âœ… è‡ªåŠ¨é€‰æ‹©3-wayæˆ–4-way split | ä¸éœ€è¦è®¡ç®—æ¯”ä¾‹ |
| 7ï¸âƒ£ ä¸€è‡´æ€§æ£€æŸ¥ | âœ… éªŒè¯å„å­é›†ç±»åˆ«åˆ†å¸ƒï¼Œè®¡ç®—JSæ•£åº¦ | ä¸éœ€è¦æ‹…å¿ƒæ•°æ®æ³„éœ² |
| 8ï¸âƒ£ å…ƒæ•°æ®è®°å½• | âœ… ä¿å­˜æ‰€æœ‰å¤„ç†è¿‡ç¨‹å’Œå‚æ•° | ä¸éœ€è¦è‡ªå·±è®°å½• |

---

## ğŸ¯ å·¥ä½œæµç¨‹å›¾

```
åŸå§‹æ•°æ® (JSON)
    â†“
[åŠ è½½æ•°æ®] â†’ æ£€æŸ¥æ–‡ä»¶å®Œæ•´æ€§
    â†“
[éªŒè¯æ•°æ®] â†’ æ£€æŸ¥ç»´åº¦ã€NaNã€ç±»åˆ«
    â†“
[æ•°æ®æ¸…ç†] â†’ å¡«å……NaNã€åˆ é™¤Inf
    â†“
[ç‰¹å¾å¤„ç†] â†’ ç”Ÿæˆè¯­ä¹‰ç‰¹å¾å
    â†“
[æ ‡å‡†åŒ–] â†’ StandardScaler
    â†“
[æ•°æ®åˆ†å‰²] â†’ 3-way/4-way splitï¼ˆè‡ªåŠ¨é€‰æ‹©ï¼‰
    â†“
[éªŒè¯ä¸€è‡´æ€§] â†’ æ£€æŸ¥åˆ†å¸ƒã€JSæ•£åº¦
    â†“
å‡†å¤‡å¥½çš„æ•°æ® âœ…
```

---

## ğŸ“– å®Œæ•´APIæ–‡æ¡£

### ç±»ï¼š`AutoDataPipeline`

#### åˆå§‹åŒ–
```python
from src.ai_training.data_pipeline import AutoDataPipeline

pipeline = AutoDataPipeline(
    data_dir: str,                    # å¿…éœ€ï¼šæ•°æ®ç›®å½•
    period: str = 'auto',             # å¯é€‰ï¼šKçº¿å‘¨æœŸï¼ˆauto/day/5min/15minç­‰ï¼‰
    enable_logging: bool = True,       # å¯é€‰ï¼šæ˜¯å¦æ‰“å°æ—¥å¿—
    random_seed: int = 42,             # å¯é€‰ï¼šéšæœºç§å­ï¼Œä¿è¯å¯å¤ç°
    min_samples_per_class: int = 20,   # å¯é€‰ï¼šæ¯ä¸ªç±»æœ€å°‘æ ·æœ¬æ•°
    imbalance_threshold: float = 2.0   # å¯é€‰ï¼šç±»åˆ«ä¸å¹³è¡¡è­¦å‘Šé˜ˆå€¼
)
```

#### è¿è¡Œç®¡é“
```python
# æ–¹æ³•1ï¼šä¸€é”®è¿è¡Œï¼Œè·å–æ‰€æœ‰æ•°æ®
X_train, y_train, X_val, y_val, X_calibrate, y_calibrate, X_test, y_test, metadata = pipeline.run()

# æ–¹æ³•2ï¼šè·å–DataFrameæ ¼å¼ï¼ˆç”¨äºAutoGluonï¼‰
train_df, val_df, calibrate_df, test_df, metadata = pipeline.run_with_dataframe()

# æ–¹æ³•3ï¼šåˆ†æ­¥æ‰§è¡Œï¼Œç›‘æ§æ¯ä¸ªé˜¶æ®µ
pipeline.load_data()
pipeline.validate_data()
pipeline.clean_data()
pipeline.engineer_features()
pipeline.standardize_data()
pipeline.split_data()
pipeline.validate_consistency()
results = pipeline.get_results()
```

#### è·å–å…ƒæ•°æ®
```python
# è·å–å®Œæ•´çš„å¤„ç†è®°å½•
metadata = pipeline.get_metadata()

print(metadata['data_statistics'])  # æ•°æ®ç»Ÿè®¡
print(metadata['processing_log'])   # å¤„ç†æ—¥å¿—
print(metadata['warnings'])          # è­¦å‘Šä¿¡æ¯
print(metadata['scalers'])          # æ ‡å‡†åŒ–å™¨ï¼ˆç”¨äºé¢„æµ‹æ—¶å¤ç°ï¼‰
```

---

## ğŸ’¡ ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹1ï¼šåŸºç¡€ä½¿ç”¨
```python
from src.ai_training.data_pipeline import AutoDataPipeline
import numpy as np

# åˆå§‹åŒ–
pipeline = AutoDataPipeline('./ai_training_data/day_kline_training')

# è¿è¡Œ
try:
    X_train, y_train, X_val, y_val, X_calibrate, y_calibrate, X_test, y_test, metadata = pipeline.run()
    print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ")
    print(f"  è®­ç»ƒé›†: {X_train.shape}")
    print(f"  æµ‹è¯•é›†: {X_test.shape}")
    
except Exception as e:
    print(f"âŒ å¤„ç†å¤±è´¥: {e}")
    print(pipeline.get_error_report())  # è·å–è¯¦ç»†é”™è¯¯æŠ¥å‘Š
```

### ç¤ºä¾‹2ï¼šç”¨äºAutoGluon
```python
from src.ai_training.data_pipeline import AutoDataPipeline
from autogluon.tabular import TabularPredictor

# è·å–DataFrame
train_df, val_df, calibrate_df, test_df, metadata = pipeline.run_with_dataframe()

# ç›´æ¥è®­ç»ƒ
predictor = TabularPredictor(label='trend', problem_type='multiclass')
predictor.fit(
    train_data=train_df,
    tuning_data=val_df,
    time_limit=3600
)

# è¯„ä¼°
test_acc = predictor.evaluate(test_df)
print(f"Test Accuracy: {test_acc:.2%}")
```

### ç¤ºä¾‹3ï¼šç›‘æ§å¤„ç†è¿‡ç¨‹
```python
pipeline = AutoDataPipeline('./data')

# åˆ†æ­¥æ‰§è¡Œï¼Œæ¯æ­¥éƒ½èƒ½æ£€æŸ¥
pipeline.load_data()
print(f"Step 1: åŠ è½½å®Œæˆï¼Œ{pipeline.get_stage_info('load')}")

pipeline.validate_data()
print(f"Step 2: éªŒè¯å®Œæˆï¼Œ{pipeline.get_stage_info('validate')}")

pipeline.clean_data()
print(f"Step 3: æ¸…ç†å®Œæˆï¼Œ{pipeline.get_stage_info('clean')}")

# ... ç»§ç»­

# è·å–æœ€ç»ˆæŠ¥å‘Š
report = pipeline.get_processing_report()
print(report)
```

---

## âš™ï¸ é…ç½®é€‰é¡¹

### æ•°æ®åˆ†å‰²ç­–ç•¥ï¼ˆè‡ªåŠ¨é€‰æ‹©ï¼‰
```
å°æ•°æ® (< 500 samples)ï¼š
  â”œâ”€ è®­ç»ƒé›†: 70%
  â”œâ”€ éªŒè¯é›†: 15%
  â””â”€ æµ‹è¯•é›†: 15%

å¤§æ•°æ® (â‰¥ 500 samples)ï¼š
  â”œâ”€ è®­ç»ƒé›†: 50%
  â”œâ”€ éªŒè¯é›†: 20%
  â”œâ”€ æ ¡å‡†é›†: 20%
  â””â”€ æµ‹è¯•é›†: 10%
```

### è‡ªå®šä¹‰é…ç½®
```python
config = {
    'scaling_method': 'standard',      # standard / minmax / robust
    'impute_strategy': 'mean',         # mean / median / most_frequent
    'split_method': 'time_series',     # time_series / random / stratified
    'validation_level': 'strict'       # strict / normal / lenient
}

pipeline = AutoDataPipeline(data_dir, config=config)
```

---

## ğŸ” æ•…éšœæ’é™¤

### é—®é¢˜1ï¼šæ•°æ®åŠ è½½å¤±è´¥
```
é”™è¯¯ä¿¡æ¯ï¼šFileNotFoundError: data directory not found
è§£å†³æ–¹æ¡ˆï¼š
  1. æ£€æŸ¥ç›®å½•è·¯å¾„æ˜¯å¦æ­£ç¡®
  2. ç¡®ä¿ç›®å½•ç»“æ„ï¼š
     data_dir/
     â”œâ”€â”€ down_trend/data.json
     â”œâ”€â”€ sideways/data.json
     â””â”€â”€ up_trend/data.json
```

### é—®é¢˜2ï¼šæ•°æ®éªŒè¯å¤±è´¥
```
é”™è¯¯ä¿¡æ¯ï¼šDataValidationError: Feature dimension mismatch
è§£å†³æ–¹æ¡ˆï¼š
  1. æ£€æŸ¥SEQUENCE_LENGTH (åº”ä¸º60)
  2. æ£€æŸ¥NUM_FEATURES (åº”ä¸º51)
  3. å¦‚æœéƒ½æ­£ç¡®ï¼Œå¯èƒ½æ˜¯raw dataé—®é¢˜
  â†’ ä½¿ç”¨ pipeline.get_debug_info() è·å–è¯¦ç»†ä¿¡æ¯
```

### é—®é¢˜3ï¼šç±»åˆ«ä¸å¹³è¡¡è­¦å‘Š
```
è­¦å‘Šä¿¡æ¯ï¼šClass imbalance ratio 3.2:1 exceeds threshold
å¤„ç†æ–¹æ³•ï¼š
  1. å¯ä»¥ç»§ç»­ä½¿ç”¨ï¼ˆæ¡†æ¶å·²å¤„ç†ï¼‰
  2. å¦‚éœ€å¹³è¡¡ï¼Œä½¿ç”¨è‡ªå®šä¹‰æƒé‡ï¼š
     class_weights = compute_class_weight('balanced', y_train)
```

### è·å–å¸®åŠ©
```python
# æŸ¥çœ‹å®Œæ•´æ—¥å¿—
pipeline.print_full_log()

# è·å–é”™è¯¯è¯Šæ–­æŠ¥å‘Š
print(pipeline.get_error_report())

# è·å–æ•°æ®ç»Ÿè®¡ä¿¡æ¯
print(pipeline.get_statistics())
```

---

## ğŸ“Š è¾“å‡ºæ•°æ®æ ¼å¼

### NumPyæ ¼å¼ï¼ˆpipeline.run()ï¼‰
```python
X_train:   shape (N, 60, 51)     # 3Dæ•°æ®ï¼š(æ ·æœ¬æ•°, æ—¶é—´æ­¥, ç‰¹å¾æ•°)
y_train:   shape (N,)             # 1Dæ ‡ç­¾ï¼š[0, 1, 2]

X_test:    shape (M, 60, 51)
y_test:    shape (M,)
```

### DataFrameæ ¼å¼ï¼ˆpipeline.run_with_dataframe()ï¼‰
```python
train_df columns:
â”œâ”€â”€ K0_open, K0_close, K0_high, ... (Kçº¿ç‰¹å¾)
â”œâ”€â”€ K1_open, K1_close, ...
â”œâ”€â”€ ...
â”œâ”€â”€ K59_volume, K59_ma20
â””â”€â”€ trend (æ ‡ç­¾ï¼š0/1/2)

# å®Œå…¨å¯ç›´æ¥ç”¨äºAutoGluon
```

### å…ƒæ•°æ®æ ¼å¼
```python
metadata = {
    'timestamp': '2024-01-15T10:30:00',
    'total_samples': 1000,
    'data_split': {'train': 700, 'val': 150, 'calibrate': 0, 'test': 150},
    'class_distribution': {'down': 333, 'sideways': 334, 'up': 333},
    'statistics': {
        'nans_found': 12,
        'nans_filled': 12,
        'infs_found': 0,
        'processing_time': 2.34  # ç§’
    },
    'warnings': [],
    'scalers': {
        'method': 'StandardScaler',
        'mean': [...],
        'std': [...]
    },
    'processing_log': [
        'Step 1: Load - OK',
        'Step 2: Validate - Found 12 NaNs',
        ...
    ]
}
```

---

## ğŸš€ é«˜çº§ç”¨æ³•

### ä¿å­˜å’Œæ¢å¤
```python
# ä¿å­˜å¤„ç†é…ç½®å’Œç»“æœ
pipeline.save_state('checkpoint.pkl')

# æ¢å¤
pipeline.load_state('checkpoint.pkl')
```

### é‡ç”¨æ ‡å‡†åŒ–å™¨
```python
# è·å–æ ‡å‡†åŒ–å™¨ï¼Œç”¨äºé¢„æµ‹é˜¶æ®µ
scaler = pipeline.get_scaler()

# åœ¨é¢„æµ‹æ—¶
X_pred_scaled = scaler.transform(X_pred_raw)
```

### æ‰¹å¤„ç†å¤šä¸ªæ•°æ®é›†
```python
from src.ai_training.data_pipeline import batch_process_pipelines

pipelines = [
    './data/day_kline_training',
    './data/5min_kline_training',
    './data/15min_kline_training'
]

results = batch_process_pipelines(pipelines)

for period, (X_train, y_train, ..., metadata) in results.items():
    print(f"Period {period}: {X_train.shape}")
```

---

## âœ… è´¨é‡ä¿è¯

### è‡ªåŠ¨è¿›è¡Œçš„æ£€æŸ¥
- âœ… æ‰€æœ‰è¾“å…¥æ•°æ®ç»´åº¦éªŒè¯
- âœ… æ•°æ®ç±»å‹æ£€æŸ¥ï¼ˆfloat32/int32ï¼‰
- âœ… NaN/Infå€¼å¤„ç†
- âœ… ç±»åˆ«åˆ†å¸ƒä¸€è‡´æ€§ï¼ˆJSæ•£åº¦ < 0.1ï¼‰
- âœ… æ ·æœ¬æ•°å……è¶³æ€§ï¼ˆæœ€å°‘60æ¡ï¼‰
- âœ… æ¯ç±»æ ·æœ¬æ•°å……è¶³æ€§ï¼ˆæœ€å°‘20æ¡ï¼‰
- âœ… æ ‡å‡†åŒ–åçš„æ— ç©·å€¼æ£€æŸ¥
- âœ… æ•°æ®æ³„éœ²æ£€æŸ¥ï¼ˆtrain/val/testä¸¥æ ¼åˆ†ç¦»ï¼‰

### æŠ¥å‘Šç¤ºä¾‹
```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âœ… æ•°æ®å¤„ç†å®ŒæˆæŠ¥å‘Š
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“Š æ•°æ®ç»Ÿè®¡
  æ€»æ ·æœ¬æ•°: 1000
  è®­ç»ƒé›†: 700 (70%)
  éªŒè¯é›†: 150 (15%)
  æµ‹è¯•é›†: 150 (15%)

ğŸ“ˆ ç±»åˆ«åˆ†å¸ƒ
  ä¸‹è·Œè¶‹åŠ¿: 333 (33.3%)
  æ¨ªç›˜éœ‡è¡: 334 (33.4%)
  ä¸Šæ¶¨è¶‹åŠ¿: 333 (33.3%)
  â†’ åˆ†å¸ƒå‡è¡¡ âœ…

ğŸ”§ æ•°æ®æ¸…ç†
  å‘ç°NaN: 12 â†’ å·²ç”¨å‡å€¼å¡«å……
  å‘ç°Inf: 0 â†’ æ— éœ€å¤„ç†
  å¼‚å¸¸å€¼: 0 â†’ æ— éœ€å¤„ç†

ğŸ“ ä¸€è‡´æ€§æ£€æŸ¥
  Jensen-Shannonæ•£åº¦: 0.0082
  â†’ åˆ†å¸ƒé«˜åº¦ä¸€è‡´ âœ…

â±ï¸ å¤„ç†è€—æ—¶
  æ€»è€—æ—¶: 2.34ç§’
  é˜¶æ®µæ—¶é—´:
    - åŠ è½½: 0.45s
    - éªŒè¯: 0.23s
    - æ¸…ç†: 0.38s
    - ç‰¹å¾å·¥ç¨‹: 0.21s
    - æ ‡å‡†åŒ–: 0.18s
    - åˆ†å‰²: 0.15s
    - éªŒè¯ä¸€è‡´æ€§: 0.34s

âš ï¸ è­¦å‘Š: æ— 
âœ… å¤„ç†çŠ¶æ€: å®Œå…¨æˆåŠŸ
```

---

## ğŸ“ å¸¸è§é—®é¢˜

**Q: å¦‚æœæ•°æ®æœ‰é—®é¢˜ï¼Œæ¡†æ¶ä¼šæ€æ ·ï¼Ÿ**
A: æ¡†æ¶ä¼šè‡ªåŠ¨ä¿®å¤å¤§éƒ¨åˆ†é—®é¢˜ï¼ˆNaNå¡«å……ã€Infè½¬NaNç­‰ï¼‰ï¼Œå¹¶åœ¨å…ƒæ•°æ®ä¸­è®°å½•ã€‚å¦‚æœæ— æ³•ä¿®å¤ï¼Œä¼šæŠ›å‡ºå…·ä½“å¼‚å¸¸ï¼Œè¯´æ˜åŸå› ã€‚

**Q: èƒ½è‡ªå®šä¹‰åˆ†å‰²æ¯”ä¾‹å—ï¼Ÿ**
A: å¯ä»¥ã€‚é€šè¿‡`config`å‚æ•°æŒ‡å®š`split_ratios`ã€‚

**Q: æ ‡å‡†åŒ–å™¨ä¿å­˜åœ¨å“ªï¼Ÿ**
A: è‡ªåŠ¨ä¿å­˜åœ¨å…ƒæ•°æ®ä¸­ã€‚`pipeline.get_metadata()['scalers']` å¯è·å–ã€‚

**Q: å¯ä»¥åœ¨é¢„æµ‹æ—¶ç”¨åŒä¸€ä¸ªæ ‡å‡†åŒ–å™¨å—ï¼Ÿ**
A: å¯ä»¥ï¼è¿™æ­£æ˜¯æ¡†æ¶çš„è®¾è®¡åˆè¡·ã€‚è§"é«˜çº§ç”¨æ³•"ä¸­çš„"é‡ç”¨æ ‡å‡†åŒ–å™¨"ã€‚

**Q: å¤„ç†å¤§æ•°æ®ä¼šå¾ˆæ…¢å—ï¼Ÿ**
A: ä¸ä¼šã€‚å¯¹äº10000æ¡æ ·æœ¬ï¼Œæ•´ä¸ªæµç¨‹é€šå¸¸ < 5ç§’ã€‚

---

## ğŸ“ æ”¯æŒ

é‡åˆ°é—®é¢˜ï¼Ÿ
1. æŸ¥çœ‹`pipeline.get_error_report()`
2. æ£€æŸ¥`pipeline.print_full_log()`
3. æŸ¥çœ‹æœ¬æ–‡æ¡£çš„"æ•…éšœæ’é™¤"éƒ¨åˆ†
4. è”ç³»å¼€å‘äººå‘˜å¹¶æä¾›`pipeline.get_debug_info()`çš„è¾“å‡º

---

## ç‰ˆæœ¬ä¿¡æ¯

| ç‰ˆæœ¬ | æ—¥æœŸ | ç‰¹æ€§ |
|------|------|------|
| 1.0 | 2024-01-15 | åˆå§‹å‘å¸ƒï¼Œæ”¯æŒAutoGluon/scikit-learn |
| 1.1 | - | (è®¡åˆ’) æ”¯æŒè‡ªå®šä¹‰å¤„ç†å™¨ |
| 2.0 | - | (è®¡åˆ’) æ”¯æŒGPUåŠ é€Ÿ |

---

**æœ€åä¸€å¥è¯ï¼šç°åœ¨ä½ åªéœ€è¦è°ƒç”¨ `AutoDataPipeline().run()` å°±å®Œäº†ï¼Œå‰©ä¸‹çš„æ¡†æ¶å…¨æå®šã€‚ğŸ‰**
