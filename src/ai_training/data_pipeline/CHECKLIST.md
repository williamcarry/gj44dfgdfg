# âœ… AutoDataPipeline è®¾ç½®æ£€æŸ¥æ¸…å•

åœ¨ä½¿ç”¨æ¡†æ¶å‰ï¼Œè¯·ç¡®ä¿ä»¥ä¸‹é¡¹ç›®å·²å®Œæˆï¼š

## ğŸ“¦ ä¾èµ–å®‰è£…

- [ ] NumPy: `pip install numpy`
- [ ] Pandas: `pip install pandas`
- [ ] scikit-learn: `pip install scikit-learn`
- [ ] SciPy: `pip install scipy`
- [ ] joblib: `pip install joblib`
- [ ] loguru (å¯é€‰): `pip install loguru`
- [ ] AutoGluon (å¦‚æœç”¨äºè®­ç»ƒ): `pip install autogluon`

æ£€æŸ¥å‘½ä»¤ï¼š
```bash
python -c "import numpy, pandas, sklearn, scipy, joblib; print('âœ… æ‰€æœ‰ä¾èµ–å·²å®‰è£…')"
```

---

## ğŸ“‚ æ–‡ä»¶ç»“æ„

- [ ] `src/ai_training/data_pipeline/__init__.py` å­˜åœ¨
- [ ] `src/ai_training/data_pipeline/pipeline.py` å­˜åœ¨
- [ ] `src/ai_training/data_pipeline/processors.py` å­˜åœ¨
- [ ] `src/ai_training/feature_extractor.py` å­˜åœ¨ï¼ˆè¢«pipelineå¯¼å…¥ï¼‰
- [ ] `src/ai_training/kline_data_loader.py` å­˜åœ¨ï¼ˆè¢«pipelineå¯¼å…¥ï¼‰

éªŒè¯å‘½ä»¤ï¼š
```bash
ls -la src/ai_training/data_pipeline/
```

---

## ğŸ—‚ï¸ æ•°æ®ç›®å½•ç»“æ„

æ£€æŸ¥ä½ çš„è®­ç»ƒæ•°æ®ç›®å½•æ˜¯å¦éµå¾ªä»¥ä¸‹ç»“æ„ï¼š

```
ai_training_data/
â”œâ”€â”€ day_kline_training/
â”‚   â”œâ”€â”€ down_trend/
â”‚   â”‚   â””â”€â”€ data.json
â”‚   â”œâ”€â”€ sideways/
â”‚   â”‚   â””â”€â”€ data.json
â”‚   â””â”€â”€ up_trend/
â”‚       â””â”€â”€ data.json
â”œâ”€â”€ 5min_kline_training/   (å¯é€‰)
â”‚   â”œâ”€â”€ down_trend/data.json
â”‚   â”œâ”€â”€ sideways/data.json
â”‚   â””â”€â”€ up_trend/data.json
â””â”€â”€ 15min_kline_training/  (å¯é€‰)
    â”œâ”€â”€ down_trend/data.json
    â”œâ”€â”€ sideways/data.json
    â””â”€â”€ up_trend/data.json
```

æ£€æŸ¥å‘½ä»¤ï¼š
```bash
ls -la ai_training_data/day_kline_training/
```

---

## ğŸ“ æ•°æ®æ–‡ä»¶éªŒè¯

å¯¹äºæ¯ä¸ª `data.json` æ–‡ä»¶ï¼Œæ£€æŸ¥ï¼š

- [ ] æ–‡ä»¶ä¸ä¸ºç©º
- [ ] JSONæ ¼å¼æ­£ç¡®ï¼ˆå¯ç”¨ `python -m json.tool` éªŒè¯ï¼‰
- [ ] åŒ…å«å¿…éœ€å­—æ®µï¼š
  - `kline_data`: Kçº¿æ•°æ®åˆ—è¡¨
  - `period`: Kçº¿å‘¨æœŸ
  - `actual_return`: å®é™…æ”¶ç›Šç‡ï¼ˆå¯é€‰ï¼‰

æ£€æŸ¥å‘½ä»¤ï¼š
```bash
python -m json.tool ai_training_data/day_kline_training/down_trend/data.json | head -20
```

---

## ğŸ”§ æ¡†æ¶é…ç½®

### å¸¸é‡éªŒè¯

ç¡®ä¿ä»¥ä¸‹å¸¸é‡æ­£ç¡®è®¾ç½®ï¼ˆåœ¨ `pipeline.py` ä¸­ï¼‰ï¼š

- [ ] `SEQUENCE_LENGTH = 60` âœ“
- [ ] `FEATURES_PER_STEP = 51` âœ“ ï¼ˆä¸ feature_extractor.py çš„ NUM_FEATURES ä¸€è‡´ï¼‰
- [ ] `TOTAL_FEATURES = 3060` âœ“ ï¼ˆ= 60 Ã— 51ï¼‰

### ç‰¹å¾æå–å™¨éªŒè¯

ç¡®ä¿ `src/ai_training/feature_extractor.py` ä¸­ï¼š

- [ ] `NUM_FEATURES = 51`
- [ ] `FEATURE_NAMES` æ˜¯é•¿åº¦ä¸º51çš„åˆ—è¡¨
- [ ] `extract_features_sequence_from_kline_data()` å‡½æ•°å­˜åœ¨ä¸”å¯ç”¨

æ£€æŸ¥å‘½ä»¤ï¼š
```python
from src.ai_training.feature_extractor import NUM_FEATURES, FEATURE_NAMES
assert NUM_FEATURES == 51
assert len(FEATURE_NAMES) == 51
print("âœ… ç‰¹å¾æå–å™¨é…ç½®æ­£ç¡®")
```

---

## ğŸ§ª æµ‹è¯•æ¡†æ¶

### æµ‹è¯•1ï¼šå¯¼å…¥æ¡†æ¶

```python
from src.ai_training.data_pipeline import AutoDataPipeline
print("âœ… AutoDataPipeline å¯¼å…¥æˆåŠŸ")
```

### æµ‹è¯•2ï¼šåˆå§‹åŒ–ï¼ˆä¸è¿è¡Œï¼‰

```python
pipeline = AutoDataPipeline('./ai_training_data/day_kline_training', enable_logging=True)
print("âœ… Pipeline åˆå§‹åŒ–æˆåŠŸ")
```

### æµ‹è¯•3ï¼šåŠ è½½æ•°æ®

```python
pipeline = AutoDataPipeline('./ai_training_data/day_kline_training')
pipeline.load_data()
print(f"âœ… åŠ è½½æ•°æ®æˆåŠŸ: {pipeline.X.shape}")
```

### æµ‹è¯•4ï¼šå®Œæ•´è¿è¡Œ

```python
pipeline = AutoDataPipeline('./ai_training_data/day_kline_training')
X_train, y_train, X_val, y_val, X_calibrate, y_calibrate, X_test, y_test, metadata = pipeline.run()
print(f"âœ… å®Œæ•´ç®¡é“è¿è¡ŒæˆåŠŸ")
print(f"   è®­ç»ƒé›†: {X_train.shape}")
print(f"   æµ‹è¯•é›†: {X_test.shape}")
```

### æµ‹è¯•5ï¼šå…ƒæ•°æ®æ£€æŸ¥

```python
metadata = pipeline.get_metadata()
assert 'timestamp' in metadata
assert 'statistics' in metadata
assert 'warnings' in metadata
print("âœ… å…ƒæ•°æ®ç»“æ„æ­£ç¡®")
```

---

## ğŸ“Š æ•°æ®è´¨é‡æ£€æŸ¥

è¿è¡Œæ¡†æ¶åï¼Œæ£€æŸ¥å…ƒæ•°æ®ï¼š

```python
metadata = pipeline.get_metadata()

# æ£€æŸ¥æ ·æœ¬æ•°
print(f"æ€»æ ·æœ¬: {metadata['statistics']['total_samples']}")
assert metadata['statistics']['total_samples'] >= 60, "æ ·æœ¬æ•°è¿‡å°‘"

# æ£€æŸ¥ç±»åˆ«åˆ†å¸ƒ
dist = metadata['class_distribution']
print(f"ç±»åˆ«åˆ†å¸ƒ: {dist}")
assert sum(dist.values()) == metadata['statistics']['total_samples']

# æ£€æŸ¥å¤„ç†è¿‡ç¨‹
print(f"å¤„ç†æ­¥éª¤æ•°: {len(metadata['processing_log'])}")
print(f"è­¦å‘Šæ•°: {len(metadata['warnings'])}")

# æ£€æŸ¥æ•°æ®åˆ†å‰²
split = metadata['data_split']
print(f"æ•°æ®åˆ†å‰²: train={split['train']}, val={split['val']}, calibrate={split['calibrate']}, test={split['test']}")
assert sum(split.values()) == metadata['statistics']['total_samples']
```

---

## ğŸš€ ä½¿ç”¨åœºæ™¯æ£€æŸ¥

### åœºæ™¯1ï¼šç”¨äºAutoGluon

- [ ] AutoGluon å·²å®‰è£…
- [ ] å¯ä»¥è¿è¡Œ `pipeline.run_with_dataframe()`
- [ ] è¿”å›çš„ DataFrame å¯ç›´æ¥ç”¨äº TabularPredictor

### åœºæ™¯2ï¼šç”¨äºè‡ªå®šä¹‰æ¨¡å‹

- [ ] å¯ä»¥è¿è¡Œ `pipeline.run()`
- [ ] è¿”å›çš„æ•°æ®å½¢çŠ¶æ­£ç¡® (N, 60, 51)
- [ ] å¯ä»¥ç›´æ¥å–‚ç»™ PyTorch/TensorFlow

### åœºæ™¯3ï¼šç”¨äºé¢„æµ‹é˜¶æ®µ

- [ ] å¯ä»¥ä¿å­˜çŠ¶æ€: `pipeline.save_state()`
- [ ] å¯ä»¥åŠ è½½çŠ¶æ€: `pipeline.load_state()`
- [ ] å¯ä»¥è·å– scaler: `pipeline.get_scaler()`

---

## ğŸ“‹ æœ€ç»ˆæ£€æŸ¥æ¸…å•

åœ¨æŠ•å…¥ä½¿ç”¨å‰ï¼Œå®Œæˆä»¥ä¸‹æ£€æŸ¥ï¼š

```python
from src.ai_training.data_pipeline import AutoDataPipeline

# 1. åˆå§‹åŒ–
pipeline = AutoDataPipeline('./ai_training_data/day_kline_training')

# 2. è¿è¡Œ
X_train, y_train, X_val, y_val, X_calibrate, y_calibrate, X_test, y_test, metadata = pipeline.run()

# 3. éªŒè¯æ•°æ®å½¢çŠ¶
assert X_train.shape[1:] == (60, 51), "ç‰¹å¾å½¢çŠ¶é”™è¯¯"
assert y_train.min() == 0 and y_train.max() == 2, "æ ‡ç­¾èŒƒå›´é”™è¯¯"
assert len(X_train) + len(X_val) + len(X_calibrate) + len(X_test) == len(X_train) + len(X_val) + len(X_calibrate) + len(X_test)

# 4. æ£€æŸ¥å…ƒæ•°æ®
assert metadata['statistics']['total_samples'] > 0
assert 'processing_log' in metadata

# 5. æ£€æŸ¥å¤„ç†çŠ¶æ€
report = pipeline.get_processing_report()
assert 'âœ…' in report or 'å®Œæˆ' in report.lower()

print("âœ…âœ…âœ… æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼æ¡†æ¶å·²å°±ç»ªã€‚")
```

---

## ğŸ†˜ å¸¸è§é—®é¢˜æ’æŸ¥

### é—®é¢˜1ï¼šImportError: No module named 'feature_extractor'

**åŸå› **: ç‰¹å¾æå–å™¨æœªå®‰è£…æˆ–è·¯å¾„ä¸å¯¹

**è§£å†³**:
```bash
# æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
ls src/ai_training/feature_extractor.py

# æ£€æŸ¥__init__.py
ls src/ai_training/__init__.py
```

### é—®é¢˜2ï¼šValueError: æ²¡æœ‰åŠ è½½åˆ°æœ‰æ•ˆæ•°æ®

**åŸå› **: æ•°æ®æ–‡ä»¶ä¸ºç©ºæˆ–æ ¼å¼é”™è¯¯

**è§£å†³**:
```bash
# æ£€æŸ¥æ•°æ®æ–‡ä»¶
wc -l ai_training_data/day_kline_training/down_trend/data.json
python -m json.tool ai_training_data/day_kline_training/down_trend/data.json
```

### é—®é¢˜3ï¼šAssertionError: ç‰¹å¾ç»´åº¦é”™è¯¯

**åŸå› **: SEQUENCE_LENGTH æˆ– NUM_FEATURES ä¸åŒ¹é…

**è§£å†³**:
```python
from src.ai_training.feature_extractor import NUM_FEATURES
print(f"NUM_FEATURES = {NUM_FEATURES}")  # åº”è¯¥æ˜¯ 51

# åœ¨ pipeline.py æ£€æŸ¥
# SEQUENCE_LENGTH = 60
# FEATURES_PER_STEP = 51
```

---

## ğŸ“ éœ€è¦å¸®åŠ©ï¼Ÿ

1. æŸ¥çœ‹ `PIPELINE_GUIDE.md` çš„"æ•…éšœæ’é™¤"éƒ¨åˆ†
2. æŸ¥çœ‹ `example_usage.py` çš„ç¤ºä¾‹
3. è¿è¡Œ `pipeline.print_full_log()` æŸ¥çœ‹è¯¦ç»†æ—¥å¿—

---

**å‡†å¤‡å¥½äº†å—ï¼Ÿå¼€å§‹ä½¿ç”¨æ¡†æ¶å§ï¼** ğŸš€
