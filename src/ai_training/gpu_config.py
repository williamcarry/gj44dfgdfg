"""
GPUé…ç½®æ¨¡å— - è‡ªåŠ¨æ£€æµ‹å¹¶é…ç½®GPUåŠ é€Ÿ

åŠŸèƒ½ï¼š
  - è‡ªåŠ¨æ£€æµ‹ç³»ç»Ÿä¸­çš„GPUè®¾å¤‡
  - é…ç½®GPUå†…å­˜å¢é•¿æ¨¡å¼
  - æ‰“å°è¯¦ç»†çš„GPUä¿¡æ¯
  - æ”¯æŒå¤šGPUç¯å¢ƒï¼ˆè‡ªåŠ¨ä½¿ç”¨ç¬¬ä¸€ä¸ªGPUï¼‰
  
ä½¿ç”¨æ–¹æ³•ï¼š
  from ai_training.gpu_config import setup_gpu
  
  # åœ¨è®­ç»ƒè„šæœ¬å¼€å§‹æ—¶è°ƒç”¨
  gpu_available, device_name = setup_gpu()
  
  if gpu_available:
      print(f"ä½¿ç”¨GPU: {device_name}")
  else:
      print("ä½¿ç”¨CPUè®­ç»ƒ")

ä½œè€…ï¼šAI Training Team
æ—¥æœŸï¼š2024-12-02
"""

import tensorflow as tf


def setup_gpu(verbose=True):
    """
    æ£€æµ‹å¹¶é…ç½®GPU
    
    å‚æ•°:
        verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯ (é»˜è®¤: True)
    
    è¿”å›:
        gpu_available: GPUæ˜¯å¦å¯ç”¨ (bool)
        device_name: è®¾å¤‡åç§° (str)
        gpu_count: GPUæ•°é‡ (int)
    """
    if verbose:
        print("\n" + "="*70)
        print("ğŸ–¥ï¸  GPUæ£€æµ‹ä¸é…ç½®")
        print("="*70)
    
    # æ£€æµ‹ç‰©ç†GPUè®¾å¤‡
    gpus = tf.config.list_physical_devices('GPU')
    gpu_count = len(gpus)
    
    if gpus:
        try:
            # è®¾ç½®GPUå†…å­˜å¢é•¿ï¼ˆé¿å…ä¸€æ¬¡æ€§å ç”¨æ‰€æœ‰æ˜¾å­˜ï¼‰
            for gpu in gpus:
                tf.config.experimental.set_memory_growth(gpu, True)
            
            if verbose:
                # æ‰“å°GPUä¿¡æ¯
                print(f"\nâœ… æ£€æµ‹åˆ° {gpu_count} ä¸ªGPUè®¾å¤‡ï¼š")
                for i, gpu in enumerate(gpus):
                    gpu_name = gpu.name.split('/')[-1]  # æå–è®¾å¤‡åç§°
                    print(f"   GPU {i}: {gpu_name}")
                
                # è·å–é€»è¾‘GPUä¿¡æ¯
                logical_gpus = tf.config.list_logical_devices('GPU')
                print(f"\nâœ… å¯ç”¨é€»è¾‘GPUæ•°é‡: {len(logical_gpus)}")
                
                # æ˜¾ç¤ºå°†ä½¿ç”¨å“ªä¸ªGPU
                print(f"\nğŸš€ è®­ç»ƒå°†ä½¿ç”¨GPUåŠ é€Ÿï¼")
                print(f"   ä½¿ç”¨è®¾å¤‡: {gpus[0].name}")
                print(f"   é¢„è®¡é€Ÿåº¦æå‡: 5-10å€ï¼ˆç›¸æ¯”CPUï¼‰")
            
            return True, gpus[0].name, gpu_count
            
        except RuntimeError as e:
            if verbose:
                print(f"\nâš ï¸  GPUé…ç½®å¤±è´¥: {e}")
                print("   å°†å›é€€åˆ°CPUè®­ç»ƒ")
            return False, "CPU", 0
            
    else:
        if verbose:
            print("\nğŸ“Š æœªæ£€æµ‹åˆ°å¯ç”¨çš„GPUè®¾å¤‡")
            print("   å°†ä½¿ç”¨CPUè®­ç»ƒ")
            print("\nğŸ’¡ æç¤ºï¼š")
            print("   - å¦‚æœæ‚¨æœ‰NVIDIAæ˜¾å¡ï¼Œè¯·ç¡®ä¿å®‰è£…äº†CUDAå’ŒcuDNN")
            print("   - TensorFlow 2.10+ å†…ç½®GPUæ”¯æŒï¼Œæ— éœ€å•ç‹¬å®‰è£…tensorflow-gpu")
            print("   - æ£€æŸ¥æ˜¾å¡é©±åŠ¨æ˜¯å¦æ­£å¸¸å®‰è£…")
            
            # æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯
            try:
                import platform
                print(f"\nğŸ’» ç³»ç»Ÿä¿¡æ¯ï¼š")
                print(f"   æ“ä½œç³»ç»Ÿ: {platform.system()} {platform.release()}")
                print(f"   TensorFlowç‰ˆæœ¬: {tf.__version__}")
            except:
                pass
        
        return False, "CPU", 0


def get_gpu_memory_info():
    """
    è·å–GPUæ˜¾å­˜ä¿¡æ¯
    
    è¿”å›:
        list: æ¯ä¸ªGPUçš„æ˜¾å­˜ä¿¡æ¯å­—å…¸åˆ—è¡¨
    """
    gpus = tf.config.list_physical_devices('GPU')
    memory_info = []
    
    for i, gpu in enumerate(gpus):
        try:
            # TensorFlow 2.x ä¸­è·å–æ˜¾å­˜ä¿¡æ¯çš„æ–¹æ³•
            gpu_details = tf.config.experimental.get_device_details(gpu)
            memory_info.append({
                'gpu_id': i,
                'name': gpu.name,
                'details': gpu_details
            })
        except:
            memory_info.append({
                'gpu_id': i,
                'name': gpu.name,
                'details': 'Not available'
            })
    
    return memory_info


def set_gpu_memory_limit(memory_limit_mb):
    """
    è®¾ç½®GPUæ˜¾å­˜é™åˆ¶
    
    å‚æ•°:
        memory_limit_mb: æ˜¾å­˜é™åˆ¶ï¼ˆMBï¼‰
    
    ç¤ºä¾‹:
        set_gpu_memory_limit(4096)  # é™åˆ¶ä¸º4GB
    """
    gpus = tf.config.list_physical_devices('GPU')
    
    if gpus:
        try:
            # ä¸ºæ¯ä¸ªGPUè®¾ç½®æ˜¾å­˜é™åˆ¶
            for gpu in gpus:
                tf.config.set_logical_device_configuration(
                    gpu,
                    [tf.config.LogicalDeviceConfiguration(memory_limit=memory_limit_mb)]
                )
            print(f"âœ… GPUæ˜¾å­˜å·²é™åˆ¶ä¸º {memory_limit_mb}MB")
        except RuntimeError as e:
            print(f"âš ï¸  è®¾ç½®æ˜¾å­˜é™åˆ¶å¤±è´¥: {e}")
            print("   æ³¨æ„: æ˜¾å­˜é™åˆ¶å¿…é¡»åœ¨ç¨‹åºåˆå§‹åŒ–GPUä¹‹å‰è®¾ç½®")
    else:
        print("âš ï¸  æœªæ£€æµ‹åˆ°GPUè®¾å¤‡")


def disable_gpu():
    """
    ç¦ç”¨GPUï¼Œå¼ºåˆ¶ä½¿ç”¨CPU
    
    ä½¿ç”¨åœºæ™¯:
        - è°ƒè¯•æ—¶æƒ³ä½¿ç”¨CPU
        - GPUæ˜¾å­˜ä¸è¶³
        - æµ‹è¯•CPUæ€§èƒ½
    """
    try:
        tf.config.set_visible_devices([], 'GPU')
        print("âœ… GPUå·²ç¦ç”¨ï¼Œå°†ä½¿ç”¨CPUè®­ç»ƒ")
    except:
        print("âš ï¸  ç¦ç”¨GPUå¤±è´¥")


if __name__ == '__main__':
    """
    æµ‹è¯•GPUé…ç½®
    """
    print("=" * 70)
    print("GPUé…ç½®æµ‹è¯•")
    print("=" * 70)
    
    # æµ‹è¯•1: åŸºæœ¬GPUæ£€æµ‹
    print("\nã€æµ‹è¯•1ã€‘åŸºæœ¬GPUæ£€æµ‹:")
    gpu_available, device_name, gpu_count = setup_gpu(verbose=True)
    print(f"\nç»“æœ: GPUå¯ç”¨={gpu_available}, è®¾å¤‡={device_name}, æ•°é‡={gpu_count}")
    
    # æµ‹è¯•2: è·å–æ˜¾å­˜ä¿¡æ¯
    if gpu_available:
        print("\nã€æµ‹è¯•2ã€‘GPUæ˜¾å­˜ä¿¡æ¯:")
        memory_info = get_gpu_memory_info()
        for info in memory_info:
            print(f"  GPU {info['gpu_id']}: {info['name']}")
            print(f"    è¯¦ç»†ä¿¡æ¯: {info['details']}")
    
    # æµ‹è¯•3: TensorFlowç‰ˆæœ¬ä¿¡æ¯
    print(f"\nã€æµ‹è¯•3ã€‘TensorFlowä¿¡æ¯:")
    print(f"  ç‰ˆæœ¬: {tf.__version__}")
    print(f"  å†…ç½®CUDAæ”¯æŒ: {tf.test.is_built_with_cuda()}")
    
    print("\n" + "=" * 70)
    print("æµ‹è¯•å®Œæˆï¼")
    print("=" * 70)
